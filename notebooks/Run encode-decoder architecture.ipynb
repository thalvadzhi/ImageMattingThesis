{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "from load_encoder_decoder import build_encoder_decoder_from_vgg\n",
    "from data_generator import DataGenerator\n",
    "from losses import overall_loss_wrapper, sad_wrapper, mse_wrapper\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATIENCE=30\n",
    "PATH_MODEL_CHECKPOINTS = \"../model_checkpoints/\"\n",
    "PATH_LOGS = \"../logs/\"\n",
    "BACKGROUNDS_PER_FG_TRAIN = 100\n",
    "BACKGROUNDS_PER_FG_TEST = 20\n",
    "BATCH_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs, model = build_encoder_decoder_from_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fg_train = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Training_set\\\\all_foregrounds\\\\\"\n",
    "bg_train = \"D:\\\\Image Matting Dataset\\\\mscoco\\\\train2014\\\\train2014\\\\\"\n",
    "a_train = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Training_set\\\\all_alphas\\\\\"\n",
    "\n",
    "fg_names_train = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Training_set\\\\training_fg_names.txt\"\n",
    "bg_names_train = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Training_set\\\\training_bg_names.txt\"\n",
    "\n",
    "\n",
    "fg_test = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Test_set\\\\Adobe-licensed images\\\\fg\\\\\"\n",
    "bg_test = \"D:\\\\Image Matting Dataset\\\\mscoco\\\\test_selected\\\\\"\n",
    "a_test = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Test_set\\\\Adobe-licensed images\\\\alpha\\\\\"\n",
    "\n",
    "fg_names_test = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Test_set\\\\test_fg_names.txt\"\n",
    "bg_names_test = \"D:\\\\Image Matting Dataset\\\\adobe dataset\\\\Combined_Dataset\\\\Test_set\\\\test_bg_names.txt\"\n",
    "\n",
    "# test_gen = DataGenerator(path_combined_test, path_alphas_test, 16, False) \n",
    "train_gen = DataGenerator(fg_names_train, bg_names_train, BACKGROUNDS_PER_FG_TRAIN, fg_train, bg_train, a_train, BATCH_SIZE, False)\n",
    "test_gen = DataGenerator(fg_names_test, bg_names_test, BACKGROUNDS_PER_FG_TEST, fg_test, bg_test, a_test, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensor_board = keras.callbacks.TensorBoard(log_dir=PATH_LOGS, histogram_freq=0, write_graph=True, write_images=True)\n",
    "model_name = PATH_MODEL_CHECKPOINTS + 'encoder_decoder.{epoch:02d}-val_loss-{val_loss:.4f}-val_sad-{val_sad:.4f}-val_mse-{val_mse:.4f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_loss', patience=PATIENCE, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=PATIENCE // 4, verbose=1)\n",
    "\n",
    "callbacks = [tensor_board, model_checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=overall_loss_wrapper(inputs), metrics=[sad_wrapper(inputs), mse_wrapper(inputs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2/2 [==============================] - 45s 23s/step - loss: 0.2821 - sad: 32.6476 - mse: 0.0970 - val_loss: 0.4163 - val_sad: 49.0796 - val_mse: 0.2269\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41632, saving model to ../model_checkpoints/encoder_decoder.01-0.4163-49.0796-0.2269.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen, validation_data=test_gen, use_multiprocessing=False, workers=1, callbacks=callbacks, shuffle=False, epochs=1, validation_steps=2, steps_per_epoch=2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
